{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d13c12-406d-4f16-bccf-45b0132dfa20",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ✅ Step 1: Load data\n",
    "Load data from Excel-file `file.xlsx` in DataFrame for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b6be765-21e0-4cac-bfad-d7080109fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_excel('C:/Users/Acer/Desktop/file.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5a2a34-2dad-47c6-b888-e0afe9e46917",
   "metadata": {},
   "source": [
    "## ✅ Step 2: Understand the Dataset\n",
    "- `df.info()`: Provides a summary of the DataFrame, including the number of columns, their names, data types, and count of non-null values.\n",
    "- `df.describe()`: Generates statistical summaries for numeric columns, including count, mean, standard deviation, minimum, maximum, and quartiles (25%, 50%, 75%).\n",
    "- `df.head()`: Displays the first 5 rows of the DataFrame for visual inspection.\n",
    "- `df.shape`: Returns the dimensions of the DataFrame (number of rows and columns).\n",
    "- `df.columns`: Lists the names of all columns in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d9bd5d-73bf-4fab-8b7f-4e4c71bf54b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 479 entries, 0 to 478\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0    Cust ID        452 non-null    object \n",
      " 1    Date           479 non-null    object \n",
      " 2   Product         479 non-null    object \n",
      " 3    Quantity       455 non-null    float64\n",
      " 4   Unit Price      461 non-null    float64\n",
      " 5   Payment Method  451 non-null    object \n",
      " 6    Comment        350 non-null    object \n",
      " 7    Amount         437 non-null    float64\n",
      "dtypes: float64(3), object(5)\n",
      "memory usage: 30.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display DataFrame structure and data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bc5ce86-6c24-44df-b3fc-829a58f0efa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Unit Price</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>455.000000</td>\n",
       "      <td>461.000000</td>\n",
       "      <td>437.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.017582</td>\n",
       "      <td>455.314534</td>\n",
       "      <td>1623.729103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.799035</td>\n",
       "      <td>368.116473</td>\n",
       "      <td>5033.686181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>71043.392545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Quantity  Unit Price         Amount\n",
       "count  455.000000   461.000000    437.000000\n",
       "mean     2.017582   455.314534   1623.729103\n",
       "std      0.799035   368.116473   5033.686181\n",
       "min      1.000000    50.000000     50.000000\n",
       "25%      1.000000   200.000000    300.000000\n",
       "50%      2.000000   350.000000    700.000000\n",
       "75%      3.000000   600.000000   1500.000000\n",
       "max      3.000000  1500.000000  71043.392545"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate statistical summary for numeric columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4ac9792-4470-48f5-8805-900faa8829d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cust ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Product</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Unit Price</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C063</td>\n",
       "      <td>2025-07-28</td>\n",
       "      <td>Phone (budget)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C021</td>\n",
       "      <td>2025-07-30</td>\n",
       "      <td>Phone (budget)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>online</td>\n",
       "      <td>Note</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C005</td>\n",
       "      <td>2025-06-15</td>\n",
       "      <td>Smartwatch (premium)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>online</td>\n",
       "      <td>Note</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C066</td>\n",
       "      <td>2025-07-13</td>\n",
       "      <td>Headphones (medium)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>online</td>\n",
       "      <td>Special</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C069</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>Phone (premium)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>Note</td>\n",
       "      <td>2400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cust ID        Date               Product    Quantity  Unit Price   \\\n",
       "0      C063  2025-07-28        Phone (budget)        1.0        300.0   \n",
       "1      C021  2025-07-30        Phone (budget)        2.0        300.0   \n",
       "2      C005  2025-06-15  Smartwatch (premium)        1.0        350.0   \n",
       "3      C066  2025-07-13   Headphones (medium)        3.0        100.0   \n",
       "4      C069  2025-07-31       Phone (premium)        3.0        800.0   \n",
       "\n",
       "  Payment Method  Comment    Amount  \n",
       "0    Credit card       NaN    300.0  \n",
       "1         online      Note    600.0  \n",
       "2         online      Note    350.0  \n",
       "3         online   Special    300.0  \n",
       "4    Credit card      Note   2400.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first 5 rows for inspection\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a2d65f4-4aae-443d-8849-7ba956692fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(479, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dimensions of the DataFrame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac35c2b4-9d8b-4351-b28f-1048e1f83c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([' Cust ID ', ' Date ', 'Product ', ' Quantity', 'Unit Price ',\n",
       "       'Payment Method', ' Comment ', ' Amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d641168-558c-439c-b138-06a772bbd57a",
   "metadata": {},
   "source": [
    "### ❓ Explanation:\n",
    "- The dataset contains 479 rows and 8 columns.\n",
    "- Missing values are present in several columns: `Cust ID` (27 missing), `Quantity` (24 missing), `Unit Price` (18 missing), `Payment Method` (28 missing), `Comment` (129 missing), and `Amount` (42 missing).\n",
    "- The `Date` column is of type `object` and will need to be converted to `datetime` in later steps.\n",
    "- Numeric columns (`Quantity`, `Unit Price`, `Amount`) show reasonable ranges, but `Amount` has a significantly high maximum value (71043.39 compared to the 75% quartile of 1500), indicating potential outliers.\n",
    "- Column names contain leading/trailing spaces (e.g., ` Cust ID `, ` Date `), which will be addressed in the data cleaning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cf3ba0-3f68-4496-a7dc-cb16246591a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ✅ Step 3: Clean Column Names\n",
    "We clean and standardize column names for consistency:\n",
    "- Remove leading/trailing spaces using `str.strip()`.\n",
    "- Convert names to lowercase and replace spaces with underscores using `str.lower()` and `str.replace()`.\n",
    "- Rename `cust_id` to `customer_id` for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40f4051b-cf39-411b-a8f7-4943e50bf275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['customer_id', 'date', 'product', 'quantity', 'unit_price',\n",
      "       'payment_method', 'comment', 'amount'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Remove leading/trailing spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Convert column names to lowercase and replace spaces with underscores\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Rename 'cust_id' to 'customer_id' for consistency\n",
    "df.rename(columns={'cust_id': 'customer_id'}, inplace=True)\n",
    "\n",
    "# Verify column names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4997bef-c53b-492b-b19d-ba89a25ad984",
   "metadata": {},
   "source": [
    "### ❓ Explanation:\n",
    "- Column names are now standardized: `customer_id`, `date`, `product`, `quantity`, `unit_price`, `payment_method`, `comment`, `amount`.\n",
    "- All spaces have been removed, and names are in lowercase with underscores for consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea56079-6a93-45e9-bd2c-1c9548163bfe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ✅ Step 4: Fix Data Types\n",
    "\n",
    "To ensure accurate date-based operations in subsequent steps, we standardize the `date` column by converting it to a consistent `datetime` format. The dataset contains mixed date formats (e.g., `2025-07-20 00:00:00` and `2025-07-20`), which require flexible parsing. We aim to remove the time component and handle invalid entries gracefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb82d3fe-2d7b-4f84-b655-85dfe1c3c25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 479 entries, 0 to 478\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   customer_id     452 non-null    object \n",
      " 1   date            479 non-null    object \n",
      " 2   product         479 non-null    object \n",
      " 3   quantity        455 non-null    float64\n",
      " 4   unit_price      461 non-null    float64\n",
      " 5   payment_method  451 non-null    object \n",
      " 6   comment         350 non-null    object \n",
      " 7   amount          437 non-null    float64\n",
      "dtypes: float64(3), object(5)\n",
      "memory usage: 30.1+ KB\n"
     ]
    }
   ],
   "source": [
    "from dateutil import parser\n",
    "import datetime\n",
    "\n",
    "def force_parse_date(x):\n",
    "    if isinstance(x, datetime.date):\n",
    "        return x\n",
    "    try:\n",
    "        return parser.parse(str(x)).date()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['date'] = df['date'].apply(force_parse_date)\n",
    "\n",
    "# Verify data types and check for missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba6a7c2-e18a-4025-ac77-f69ff8173dd6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ❓ Explanation:\n",
    "- We define a custom function `force_parse_date` using the `dateutil.parser` library to parse various date formats into `datetime.date` objects, stripping any time components.\n",
    "- The function checks if the input is already a `datetime.date` object to avoid redundant processing, attempts to parse string inputs, and returns `None` for unparseable values.\n",
    "- The `apply` method processes each value in the `date` column, ensuring all valid dates are standardized.\n",
    "- We verify the results using `df.info()` to check the data type and remaining missing values, and inspect rows with `None` to identify any persistent issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d028da0-e381-4309-bd96-4da6e342ab6e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ✅ Step 5: Remove Duplicates\n",
    "We remove duplicate rows to ensure each record is unique:\n",
    "- Use `df.drop_duplicates()` to delete fully identical rows.\n",
    "- Verify the new dataset size with `df.shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86d447e7-a63c-4b93-b4ce-bcf35a4f76ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(479, 8)\n",
      "(477, 8)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "# Remove duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Verify the new shape of the DataFrame\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e9aa3e-aabb-4b9e-bbdb-fc73f9a787a7",
   "metadata": {},
   "source": [
    "### ❓ Explanation:\n",
    "- Removed 2 duplicate rows.\n",
    "- The dataset is now free of duplicate records, ready for further cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2309b32-1804-4109-a6f1-e0b00cfdf009",
   "metadata": {},
   "source": [
    "## ✅ Step 6: Check Missing Values\n",
    "Missing values in `date`, `amount`, and other columns can affect analysis. We quantify these gaps to guide imputation strategies, confirming the success of date parsing from Step 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf598a54-00a7-451b-b651-8090e2663056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_id        27\n",
      "date                0\n",
      "product             0\n",
      "quantity           24\n",
      "unit_price         18\n",
      "payment_method     28\n",
      "comment           129\n",
      "amount             42\n",
      "dtype: int64\n",
      "Rows with missing 'date':\n",
      "Empty DataFrame\n",
      "Columns: [customer_id, date, product, payment_method, comment, amount]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Inspect rows with missing 'date'\n",
    "print(\"Rows with missing 'date':\")\n",
    "print(df[df['date'].isna()][['customer_id', 'date', 'product', 'payment_method', 'comment', 'amount']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fd945d-7259-4a59-851f-d02023cab271",
   "metadata": {},
   "source": [
    "### ❓ Observations:\n",
    "- Missing values: `customer_id` (27), `date` (0), `quantity` (24), `unit_price` (18) `payment_method` (28), `comment` (129), `amount` (42).\n",
    "- No missing values in `date`, confirming successful parsing in Step 4.\n",
    "- High missing rates in `comment` and `amount` highlight areas for imputation in Step 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06df3d77-0b46-4b95-b2bc-e38e8a7972dc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ✅Step 7: Check Outliers\n",
    "Outliers in `quantity` or `unit_price` may indicate data errors that contribute to incorrect `amount` values, such as 71043.39. We use the Interquartile Range (IQR) method to identify these anomalies, preserving all transactions for correction in Step 8 to maintain the integrity of sales data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c0078cd-bf80-4d5b-922c-1f61f4d48ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in 'quantity' or 'unit_price':\n",
      "     quantity  unit_price        amount\n",
      "23        1.0      1500.0   1500.000000\n",
      "87        3.0      1500.0   4500.000000\n",
      "115       2.0      1500.0   3000.000000\n",
      "125       1.0      1500.0   1500.000000\n",
      "127       1.0      1500.0   1500.000000\n",
      "170       NaN      1500.0           NaN\n",
      "203       2.0      1500.0   3000.000000\n",
      "219       2.0      1500.0   3000.000000\n",
      "225       3.0      1500.0   4500.000000\n",
      "239       1.0      1500.0   1500.000000\n",
      "251       2.0      1500.0   3000.000000\n",
      "269       2.0      1500.0   3000.000000\n",
      "272       1.0      1500.0   1500.000000\n",
      "273       2.0      1500.0   3000.000000\n",
      "282       3.0      1500.0   4500.000000\n",
      "287       3.0      1500.0   4500.000000\n",
      "303       1.0      1500.0   1500.000000\n",
      "351       3.0      1500.0  71043.392545\n",
      "360       2.0      1500.0   3000.000000\n",
      "392       3.0      1500.0   4500.000000\n",
      "403       3.0      1500.0   4500.000000\n",
      "420       3.0      1500.0   4500.000000\n",
      "442       2.0      1500.0   3000.000000\n",
      "443       NaN      1500.0           NaN\n",
      "455       2.0      1500.0   3000.000000\n",
      "456       3.0      1500.0   4500.000000\n",
      "\n",
      "Dataset shape: (477, 8)\n"
     ]
    }
   ],
   "source": [
    "# Calculate IQR for 'quantity'\n",
    "Q1_qty = df['quantity'].quantile(0.25)\n",
    "Q3_qty = df['quantity'].quantile(0.75)\n",
    "IQR_qty = Q3_qty - Q1_qty\n",
    "lower_bound_qty = Q1_qty - 1.5 * IQR_qty\n",
    "upper_bound_qty = Q3_qty + 1.5 * IQR_qty\n",
    "\n",
    "# Calculate IQR for 'unit_price'\n",
    "Q1_price = df['unit_price'].quantile(0.25)\n",
    "Q3_price = df['unit_price'].quantile(0.75)\n",
    "IQR_price = Q3_price - Q1_price\n",
    "lower_bound_price = Q1_price - 1.5 * IQR_price\n",
    "upper_bound_price = Q3_price + 1.5 * IQR_price\n",
    "\n",
    "# Identify outliers\n",
    "outliers = df[(df['quantity'] < lower_bound_qty) | (df['quantity'] > upper_bound_qty) |\n",
    "              (df['unit_price'] < lower_bound_price) | (df['unit_price'] > upper_bound_price)]\n",
    "print(\"Outliers in 'quantity' or 'unit_price':\")\n",
    "print(outliers[['quantity', 'unit_price', 'amount']])\n",
    "print()\n",
    "# No removal, keep all rows\n",
    "print(\"Dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebb2426-5e23-48ec-b1c9-55bfe1e74c23",
   "metadata": {},
   "source": [
    "### ❓ Explanation:\n",
    "- Identified 26 outliers in `quantity` or `unit_price`, primarily with `unit_price = 1500.0` and `quantity` ranging from 1.0 to 3.0.  \n",
    "- Most outliers were valid transactions, with `amount` aligning with `quantity` * `unit_price` (e.g., 3.0 * 1500.0 = 4500.0), except for errors like `amount = 71043.39`.  \n",
    "- Two outliers had missing `quantity` values, consistent with the 24 missing entries in `quantity`.  \n",
    "- No rows were removed, preserving all 477 rows and 8 columns to avoid losing valid sales data.  \n",
    "- Errors in `amount` will be corrected in Step 8 by recalculating `quantity` * `unit_price` for all rows.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280e340c-15df-409b-871b-4ec36680f1b1",
   "metadata": {},
   "source": [
    "## ✅ Step 8: Handle Missing Values\n",
    "Missing values in `quantity`, `unit_price`, `amount`, and other columns require imputation. We recalculate `amount` for all rows to correct errors and ensure data consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3e1cad1-098d-455b-97de-4c195ca45e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 477 entries, 0 to 478\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   customer_id     477 non-null    object        \n",
      " 1   date            477 non-null    datetime64[ns]\n",
      " 2   product         477 non-null    object        \n",
      " 3   quantity        477 non-null    float64       \n",
      " 4   unit_price      477 non-null    float64       \n",
      " 5   payment_method  477 non-null    object        \n",
      " 6   comment         477 non-null    object        \n",
      " 7   amount          477 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(3), object(4)\n",
      "memory usage: 33.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values\n",
    "df['quantity'] = df['quantity'].fillna(df['quantity'].mean())\n",
    "df['unit_price'] = df['unit_price'].fillna(df['unit_price'].mean())\n",
    "df['customer_id'] = df['customer_id'].fillna(df['customer_id'].mode()[0])\n",
    "df['payment_method'] = df['payment_method'].fillna(df['payment_method'].mode()[0])\n",
    "df['comment'] = df['comment'].fillna('No Comment')\n",
    "df['date'] = df['date'].fillna(df['date'].mode()[0])\n",
    "\n",
    "# Recalculate 'amount' for all rows\n",
    "df['amount'] = df['quantity'] * df['unit_price']\n",
    "\n",
    "# Convert 'date' to datetime64\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Verify no missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398c28c8-25aa-439d-9488-5d0707e24d4a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ❓ Observations:  \n",
    "**Observations**:\n",
    "- Filled missing values: `customer_id` (27), `quantity` (24), `unit_price` (18), `payment_method` (28), `comment` (129), `date` (0, prophylactically).\n",
    "- Recalculated `amount` for all 477 rows, correcting errors like 71043.39.\n",
    "- Converted `date` from `object` to `datetime64` for Step 12.\n",
    "- No missing values remain, dataset has 477 rows and 8 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a15b22-127b-47e7-afbf-8da2a0a8c6c7",
   "metadata": {},
   "source": [
    "## ✅ Step 9: Fix Label Inconsistencies\n",
    "Inconsistent labels in the `payment_method` column, such as variations in case ('CC' vs 'cc') or abbreviations ('online' vs 'Online'), can lead to errors in analysis. We standardize these values to ensure consistency and facilitate accurate grouping in subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26dd38fc-34ca-4309-89da-25ac69f3245a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "payment_method\n",
      "credit card       203\n",
      "cash              178\n",
      "online_payment     96\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['payment_method'] = df['payment_method'].str.lower().replace({'cc': 'credit_card', 'online': 'online_payment'})\n",
    "print(df['payment_method'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6675e265-15c7-4c6f-ac03-b3308063eeb0",
   "metadata": {},
   "source": [
    "### ❓ Explanation:  \n",
    "**Observations**:\n",
    "- Standardized `payment_method` values, resulting in three categories: `credit card` (203), `cash` (178), `online_payment` (96).\n",
    "- Eliminated case variations and abbreviations, ensuring consistency across all 477 rows.\n",
    "- Verified with `value_counts()` that no missing or inconsistent labels remain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0084e086-b9fb-44ab-be13-3cf037948fcb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ✅ Step 10: Drop Unnecessary Columns\n",
    "The `comment` column, with approximately 27% missing values filled with 'No Comment' in Step 8, provides limited analytical value. We remove it to streamline the dataset and focus on columns critical for subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81054d14-76d3-48f2-8892-bb72330040de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['customer_id', 'date', 'product', 'quantity', 'unit_price',\n",
      "       'payment_method', 'amount'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['comment'])\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fdc5cc-9aa5-45ed-96d8-9b77652872bc",
   "metadata": {},
   "source": [
    "### ❓ Explanation:\n",
    "- Removed the `comment` column, which had 129 missing values filled with 'No Comment' in Step 8.  \n",
    "- Reduced the dataset to 7 columns: `customer_id`, `date`, `product`, `quantity`, `unit_price`, `payment_method`, and `amount`.  \n",
    "- Verified with `df.columns` that the dataset, retaining 477 rows, is now streamlined for efficient analysis in subsequent steps.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df3864c-cd12-4ac4-b38b-ed7c8c8669cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ✅ Step 11: Create New Columns\n",
    "To validate the `amount` column, we create a new column to check if `amount` equals `quantity` * `unit_price`, ensuring data consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d923595-8341-4901-b2dd-3ed2ea078c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   quantity  unit_price  amount  amount_check\n",
      "0       1.0       300.0   300.0         300.0\n",
      "1       2.0       300.0   600.0         600.0\n",
      "2       1.0       350.0   350.0         350.0\n",
      "3       3.0       100.0   300.0         300.0\n",
      "4       3.0       800.0  2400.0        2400.0\n",
      "5       2.0       600.0  1200.0        1200.0\n",
      "6       1.0       200.0   200.0         200.0\n",
      "7       3.0       350.0  1050.0        1050.0\n",
      "8       1.0       600.0   600.0         600.0\n",
      "9       2.0       300.0   600.0         600.0\n"
     ]
    }
   ],
   "source": [
    "df['amount_check'] = df['quantity'] * df['unit_price']\n",
    "print(df[['quantity', 'unit_price', 'amount', 'amount_check']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc01ee2-0c49-4609-8fbd-8880a416fb9d",
   "metadata": {},
   "source": [
    "### ❓ Explanation:\n",
    "- We calculate `amount_check` as `quantity` * `unit_price` to verify the `amount` column's accuracy.\n",
    "- A sample of rows is displayed to compare `amount` and `amount_check`, identifying any discrepancies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcc99d3-13ef-4315-9d0e-c46dd9603864",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ✅ Step 12: Split Date into Year and Month\n",
    "To facilitate time-based analysis, we extract the year and month from the `date` column into separate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "088971a2-a105-4f90-970b-8967380d33b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  year  month\n",
      "0 2025-07-28  2025      7\n",
      "1 2025-07-30  2025      7\n",
      "2 2025-06-15  2025      6\n",
      "3 2025-07-13  2025      7\n",
      "4 2025-07-31  2025      7\n"
     ]
    }
   ],
   "source": [
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "print(df[['date', 'year', 'month']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7011282-4383-45ae-af35-3f05c76dbf2c",
   "metadata": {},
   "source": [
    "### ❓ Explanation: \n",
    "- We use `dt.year` and `dt.month` to extract the year and month from the `date` column.\n",
    "- A sample of rows is displayed to confirm the new columns are correctly populated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ba4421-f2f8-441b-8660-4cd32d286ac6",
   "metadata": {},
   "source": [
    "## ✅ Step 13: Save Cleaned Data\n",
    "The cleaned and processed dataset is saved for further analysis or sharing, ensuring all transformations are preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90612c1b-5cb9-4a73-865a-c1f6c318c18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'cleaned_data.csv'\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 477 entries, 0 to 478\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   customer_id     477 non-null    object        \n",
      " 1   date            477 non-null    datetime64[ns]\n",
      " 2   product         477 non-null    object        \n",
      " 3   quantity        477 non-null    float64       \n",
      " 4   unit_price      477 non-null    float64       \n",
      " 5   payment_method  477 non-null    object        \n",
      " 6   amount          477 non-null    float64       \n",
      " 7   amount_check    477 non-null    float64       \n",
      " 8   year            477 non-null    int32         \n",
      " 9   month           477 non-null    int32         \n",
      "dtypes: datetime64[ns](1), float64(4), int32(2), object(3)\n",
      "memory usage: 37.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('C:/Users/Acer/Desktop/cleaned_data.csv', index=False)\n",
    "print(\"Data saved to 'cleaned_data.csv'\")\n",
    "print()\n",
    "# Display DataFrame structure and data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611f151a-d543-455f-8699-b689ea0af39d",
   "metadata": {},
   "source": [
    "### ❓ Explanation:\n",
    "- We use `df.to_csv()` to save the DataFrame to a CSV file named `cleaned_data.csv`.\n",
    "- The `index=False` parameter prevents saving the DataFrame index as a column.\n",
    "- A confirmation message verifies the operation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
